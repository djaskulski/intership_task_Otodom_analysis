{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "568bd61d-5509-4c55-8c9f-7e3366264e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8dd432-4808-46d5-914b-db6af420c89c",
   "metadata": {},
   "source": [
    "# DP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "370ffbc8-7736-413b-8834-8856cedbcb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_otodom():\n",
    "    \"\"\"Load csv files with defined column names\"\"\"\n",
    "    \n",
    "    data_ads_cols = [\"date\", \"user_id\", \"ad_id\", \"category_id\", \"params\"]\n",
    "    data_replies_cols = [\"date\", \"user_id\", \"ad_id\", \"mails\", \"phones\"]\n",
    "    data_segmentation_cols = [\"user_id\", \"segment\"]\n",
    "    data_categories_cols = [\"category_id\", \"category_name\"]\n",
    "\n",
    "    # here you can find information about the announcements\n",
    "    data_ads_df = pd.read_csv(\"data/data_ads.csv\", delimiter=\";\", names=data_ads_cols)\n",
    "    # information about the response per advertisement per day\n",
    "    data_replies_df = pd.read_csv(\"data/data_replies.csv\", delimiter=\";\", names=data_replies_cols)\n",
    "    # segmentation mapping for each user\n",
    "    data_segments_df = pd.read_csv(\"data/data_segments.csv\", delimiter=\";\", names=data_segmentation_cols)\n",
    "    # mapping to category tree\n",
    "    data_categories_df = pd.read_csv(\"data/data_categories.csv\", delimiter=\";\", names=data_categories_cols)\n",
    "    \n",
    "    return [data_ads_df, data_replies_df, data_segments_df, data_categories_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "7b6d777b-f117-4a04-bbb0-0799ad788c86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_info(source):\n",
    "    \"\"\"Check columns type for each DataFrame\"\"\"\n",
    "    \n",
    "    print(\"Checking info: \\n\")\n",
    "    \n",
    "    for df in source:\n",
    "        print (df.info(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "8fd1a6bd-72a5-48a1-a7a9-175a783b6738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_missing(source, column):\n",
    "    \"\"\"Cut rows with missing values from original source and make new df with only null values\"\"\"\n",
    "    \n",
    "    data_replies_df = source\n",
    "    null_indices =  data_replies_df[data_replies_df[\"phones\"].isnull()].index.tolist()\n",
    "\n",
    "    # cutting nulls\n",
    "    null_list = []\n",
    "    for i in null_indices:\n",
    "           null_list.append(data_replies_df.iloc[i])\n",
    "\n",
    "    # dropping nulls\n",
    "    not_null_replies = data_replies_df.drop(null_indices)\n",
    "    not_null_replies.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # new DataFrame with missing values\n",
    "    data_replies_cols = [\"date\", \"user_id\", \"ad_id\", \"mails\", \"phones\"]\n",
    "    null_replies = pd.DataFrame(null_list, columns=data_replies_cols)\n",
    "    null_replies.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # saving to csv\n",
    "    null_replies.to_csv(\"data/null_replies.csv\")\n",
    "    not_null_replies.to_csv(\"data/not_null_replies.csv\")\n",
    "    \n",
    "    return [null_replies, not_null_replies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "4716ba97-617f-4df1-b718-430c0e6b1128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_replies():\n",
    "    \"\"\"Load csv files with null/not null replies\"\"\"\n",
    "    \n",
    "    #data_replies_cols = [\"date\", \"user_id\", \"ad_id\", \"mails\", \"phones\"]\n",
    "    \n",
    "    # segmentation mapping for each user\n",
    "    null_replies = pd.read_csv(\"data/null_replies.csv\")#, names=data_replies_cols)\n",
    "    # mapping to category tree\n",
    "    not_null_replies = pd.read_csv(\"data/not_null_replies.csv\")#, names=data_replies_cols)\n",
    "    \n",
    "    return [null_replies, not_null_replies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "472d57c6-b750-419e-8812-a7da5913984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing(source, df_names, ):\n",
    "    \"\"\" \"\"\"\n",
    "    \n",
    "    for df, names in zip(source, df_names):\n",
    "        print(f\"Missing in {names} %\\n\",round(df.isnull().sum()/len(df)*100, 2),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "a68f618f-9819-4c03-bb71-1f253c906c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_split(source):\n",
    "    \"\"\" \"\"\"\n",
    "    \n",
    "    # features\n",
    "    X = source.iloc[:,0:4]\n",
    "    # target\n",
    "    y = source.iloc[:,4]\n",
    "    \n",
    "    # split into train=0.8, test=0.2\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "    \n",
    "    return [X_train, X_test, y_train, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "7ad914de-6684-4e63-b293-b19740ec8c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_pipe_model(X_train, X_test, y_train, y_test, to_pred):\n",
    "    \"\"\" \"\"\"\n",
    "    \n",
    "    to_pred.drop([\"phones\"], axis=1, inplace=True)\n",
    "    splits = [X_train, X_test, to_pred]\n",
    "    \n",
    "    for split in splits:\n",
    "        #split[\"date\"] = pd.to_datetime(split[\"date\"])\n",
    "        \n",
    "        split[\"date\"] = pd.to_datetime(split[\"date\"])\n",
    "        split[\"date\"] = split[\"date\"].apply(lambda x: x.toordinal())\n",
    "\n",
    "    \n",
    "    \n",
    "    # pipeline\n",
    "    pipe = Pipeline([(\"regressor\", LinearRegression())])\n",
    "    \n",
    "    search_space = [\n",
    "    {\"regressor\": [LinearRegression()]},\n",
    "    {\"regressor\": [Ridge()],\n",
    "    \"regressor__alpha\": np.linspace(0, 0.2, 21),\n",
    "    \"regressor__max_iter\": [1000]},\n",
    "    {\"regressor\": [Lasso()],\n",
    "    \"regressor__alpha\": np.linspace(0, 0.2, 21),\n",
    "    \"regressor__max_iter\": [1000]}\n",
    "]\n",
    "    # gridsearch, fit, predict\n",
    "    gridsearch = GridSearchCV(pipe, search_space, cv=5, verbose=1, n_jobs=-1)\n",
    "    best_model = gridsearch.fit(X_train, y_train)\n",
    "    preds = best_model.predict(to_pred)\n",
    "     \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "b30c674f-ad0d-4c88-b56c-1eac8ff1ed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_replies(source_1, source_2, pred):\n",
    "    \"\"\" \"\"\"\n",
    "    \n",
    "    # join DataFrames\n",
    "    replies_1 = source_1\n",
    "    replies_2 = source_2\n",
    "    replies_2[\"phones\"] = pred\n",
    "    data_replies = replies_1.append(replies_2, ignore_index=True)\n",
    "    \n",
    "    return data_replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "2e0f5d34-d510-4ef7-993e-ecbd5ca15996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dp_job():\n",
    "    # List of OLX DataFrames\n",
    "    data_ads_df, data_replies_df, data_segments_df, data_categories_df = load_otodom()\n",
    "    # Returns: [data_ads_df, data_replies_df, data_segments_df, data_categories_df]\n",
    "    \n",
    "    \n",
    "#     # DataFrame: data_replies_df\n",
    "#     data_replies_df = data[1]\n",
    "    \n",
    "#     # Names of splitted DataFrames\n",
    "    \n",
    "    \n",
    "    # Check info\n",
    "    #check_info(source=data)\n",
    "    # Returns: None\n",
    "    \n",
    "     # Try load files from csv or make new\n",
    "    try:\n",
    "        null_replies, not_null_replies = load_replies()\n",
    "    except Exception as e:\n",
    "           print(\"Error has occurred: \", e, \"\\n\")\n",
    "    finally:\n",
    "        # Split original source into two pieces [null/not null] ans save it to csv\n",
    "        null_replies, not_null_replies = cut_missing(source=data_replies_df, column=\"phones\")\n",
    "        # Returns: [null_replies, not_null_replies]\n",
    "\n",
    "        \n",
    "    print(\"len null replies:\", len(null_replies))\n",
    "    print(\"len not null replies:\", len(not_null_replies))\n",
    "    \n",
    "    # Select features, target and split it\n",
    "    X_train, X_test, y_train, y_test = select_split(source=not_null_replies)\n",
    "    # Retruns:  [X_train, X_test, y_train, y_test]\n",
    "    \n",
    "    splitted = [X_train, X_test, y_train, y_test]\n",
    "    split_names = [\"X_train\", \"X_test\", \"X_val\", \"y_train\", \"y_test\", \"y_val\"]\n",
    "    # Check percent of missing values \n",
    "    check_missing(source=splitted, df_names=split_names)\n",
    "    # Returns: None\n",
    "    \n",
    "    # Classification WIP\n",
    "    preds = best_pipe_model(X_train, X_test, y_train, y_test, to_pred=null_replies)\n",
    "    # Returns: preds\n",
    "    print(\"len preds:\", len(preds))\n",
    "    \n",
    "    new_data_replies = join_replies(source_1=not_null_replies, source_2=null_replies, pred=preds)\n",
    "    # Returns data_replies\n",
    "    \n",
    "    # Update list of DataFrames\n",
    "    data_replies_df = new_data_replies\n",
    "    \n",
    "    return [data_ads_df, data_replies_df, data_segments_df, data_categories_df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b2a5c6-f646-45e7-85ca-2fbec8e83367",
   "metadata": {},
   "source": [
    "# SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "0c2f5f8b-46a2-4181-884a-fe3c28d25082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqlite3_connect(db_file):\n",
    "    \"\"\"Establish connection with local database\"\"\"\n",
    "    \n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        print(\"Connected to sqlite3 ver: \", sqlite3.version)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "d22b7a57-a2be-4fce-a9ce-b1fdcf739e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqlite3_insert(source, tables, connection):\n",
    "    \"\"\"Insert data to the database from DataFrames\"\"\"\n",
    "    \n",
    "    # [data_ads_df, data_replies_df, data_segments_df, data_categories_df]\n",
    "    indices = [0, 1, 2, 3]\n",
    "    \n",
    "    for i, tab in zip(indices, tables):\n",
    "        source[i].to_sql(tab, connection, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "10dabcf9-a48b-407a-bbcc-cf81ec2c05aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqlite3_query(connection):#, query):\n",
    "    \"\"\"Create a table from table_query statement\"\"\"\n",
    "    \n",
    "#     try:\n",
    "#         connection.execute(query)\n",
    "#         print(\"Query send!\")\n",
    "#     except Error as e:\n",
    "#         print(e)\n",
    "        \n",
    "        \n",
    "    sql = \"SELECT * FROM replies WHERE phones >  40;\"\n",
    "    response_df = pd.read_sql_query(sql, connection)\n",
    "    return response_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "5243b75b-003a-4abe-9728-59eb35428391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_job(source):\n",
    "    database = r\"otodom.db\"\n",
    "    table_list = [\"ads\", \"replies\", \"segments\", \"categories\"]\n",
    "    sql_my_query = \" \"\n",
    "    \n",
    "    conn = sqlite3_connect(database)\n",
    "    \n",
    "    if conn is not None:\n",
    "        sqlite3_insert(source=source, tables=table_list, connection=conn)\n",
    "        query = sqlite3_query(connection=conn)#, query=sql_my_query)\n",
    "        print(query)\n",
    "        #sqlite3_query(connection=conn, query=sql_my_query)\n",
    "        #sqlite3_query(connection=conn, query=sql_my_query)\n",
    "        print(\"SQL job is done.\")\n",
    "    else:\n",
    "        print(\"Error! cannot create the database connection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dca0a7-4d84-400f-8e3d-0033d58621e7",
   "metadata": {},
   "source": [
    "# LIQUIDITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645e7dfb-a2a7-4a2f-bbf2-3150a99f53b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec84362-7b9c-4eed-bf0a-4216d7b39ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba184e2-4e5f-499e-b6ef-28d60698b599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "8c0dc425-38b5-4455-9e44-3945956cee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def liquidity_per_user():\n",
    "    \"\"\"\n",
    "    Liquidity will be understood as % of advertisements which have received \n",
    "    at least 1 response (by phone or e-mail) within a period of 7 days \n",
    "    (including day 0 - the day of adding an day of adding an ad)\n",
    "    \"\"\"\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "bce8d80e-2ea7-4ffe-8cd5-5cf79aaa44ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_data_analysis():\n",
    "    \"\"\" \n",
    "    Jupyter/R Markdown preferred for analysis\n",
    "\n",
    "    Scripts can be in separate files, or as part of a notebook depending on\n",
    "    selected methods\n",
    "\n",
    "    Please present your final results and most important conclusions in the \n",
    "    form of a presentation (e.g. Google slides)\n",
    "    \"\"\"\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "b6d17435-9c23-4336-8485-bd0b4b36e8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_1():\n",
    "    \"\"\" \n",
    "    What differences do you see between the segments in terms of the data \n",
    "    you have available (including liquidity)?\n",
    "    \"\"\"\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "fa1420e8-58e7-4bba-b09c-d83e11f56002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_2():\n",
    "    \"\"\"What do you think might influence higher or lower levels of liquidity?\"\"\"\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9a8c24-5610-4e07-b92e-eacd1863dc66",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "b03ed3cc-4ef6-41b8-a465-e1f168a06583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # Predict missing values with LinearRegression\n",
    "    data = dp_job()\n",
    "    \n",
    "    # Make db, insert data from df\n",
    "    sql_job(source=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "1f469aad-dd2d-419e-89d7-a76c89050590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len null replies: 110268\n",
      "len not null replies: 643009\n",
      "Missing in X_train %\n",
      " date       0.0\n",
      "user_id    0.0\n",
      "ad_id      0.0\n",
      "mails      0.0\n",
      "dtype: float64 \n",
      "\n",
      "Missing in X_test %\n",
      " date       0.0\n",
      "user_id    0.0\n",
      "ad_id      0.0\n",
      "mails      0.0\n",
      "dtype: float64 \n",
      "\n",
      "Missing in X_val %\n",
      " 0.0 \n",
      "\n",
      "Missing in y_train %\n",
      " 0.0 \n",
      "\n",
      "Fitting 5 folds for each of 43 candidates, totalling 215 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done 215 out of 215 | elapsed:   31.8s finished\n",
      "C:\\Users\\DJaskulski\\miniconda3\\envs\\olx_otodom\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.51535e-20): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len preds: 110268\n",
      "Connected to sqlite3 ver:  2.6.0\n",
      "         date  user_id     ad_id  mails  phones\n",
      "0  2019-04-14  2435764  58744356      0    48.0\n",
      "1  2019-04-14  2435764  58743964      0    51.0\n",
      "2  2019-04-14  2435764  58744404      0    72.0\n",
      "SQL job is done.\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    %time main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987a2ba3-dcb8-4d1e-adf4-a736e9e03632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:olx_otodom] *",
   "language": "python",
   "name": "conda-env-olx_otodom-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
